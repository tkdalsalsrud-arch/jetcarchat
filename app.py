import streamlit as st
import google.generativeai as genai
import os
import pandas as pd
from pathlib import Path

# --- 0. í˜ì´ì§€ ì„¤ì • ë° CSS ìŠ¤íƒ€ì¼ ---
st.set_page_config(page_title="JETCAR ì±—ë´‡", page_icon="ğŸš—")

st.markdown("""
<style>
    /* ì±— ë©”ì‹œì§€ ì»¨í…Œì´ë„ˆ ìŠ¤íƒ€ì¼ */
    div[data-testid="chat-message-container"] {
        border-radius: 10px;
        padding: 10px 14px;
        margin-bottom: 10px;
    }
    /* ì‚¬ìš©ì(user) ë©”ì‹œì§€ ë°°ê²½ìƒ‰ */
    div[data-testid="chat-message-container"]:has(div[data-testid="stChatMessageContent-user"]) {
        background-color: #F0F2F6;
        color: #333;
    }
    /* ë´‡(assistant) ë©”ì‹œì§€ ë°°ê²½ìƒ‰ */
    div[data-testid="chat-message-container"]:has(div[data-testid="stChatMessageContent-assistant"]) {
        background-color: #4A90E2;
        color: white;
    }
    /* ì…ë ¥ í¼ ì»¨í…Œì´ë„ˆ ìŠ¤íƒ€ì¼ */
    div[data-testid="stForm"] {
        background-color: #f9f9f9;
        padding: 20px;
        border-radius: 10px;
        border: 1px solid #ddd;
    }
    /* ì±„íŒ… ì…ë ¥ì°½ ì—¬ë°± ì¡°ì • */
    .stChatInputContainer {
        padding-top: 15px !important;
    }
    /* í¼ ë‚´ë¶€ ì„¹ì…˜ í—¤ë” ìŠ¤íƒ€ì¼ */
    .form-header {
        font-size: 1.1em;
        font-weight: bold;
        color: #444;
        margin-top: 10px;
        margin-bottom: 5px;
    }
</style>
""", unsafe_allow_html=True)

# --- 1. API í‚¤ ì„¤ì • ---
try:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
except Exception as e:
    st.error("ğŸš¨ [Gemini API í‚¤]ë¥¼ ì„¤ì •í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. Secretsë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()

# --- 2. ì•± ì œëª© ---
st.title("ğŸš— JETCAR ë§ì¶¤í˜• ìƒë‹´ ì±—ë´‡")
st.caption("Powered by Streamlit & Google Gemini")

# --- 3. Excel ë°ì´í„° ë¡œë”© (ì¶œê³  ê°€ëŠ¥ ì°¨ëŸ‰) ---
try:
    context_file = Path("cars_data.xlsx")
    if not context_file.exists():
        st.error("ğŸš¨ 'cars_data.xlsx' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. app.pyì™€ ê°™ì€ ìœ„ì¹˜ì— ë§Œë“¤ì–´ì£¼ì„¸ìš”.")
        st.stop()
    
    # openpyxl ì—”ì§„ ì‚¬ìš©
    df = pd.read_excel(context_file, engine="openpyxl")
    
    # ë°ì´í„°í”„ë ˆì„ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (AIì—ê²Œ ì œê³µí•  ì»¨í…ìŠ¤íŠ¸)
    context = "--- [ì œíŠ¸ì¹´ í˜„ì¬ ë³´ìœ  ì°¨ëŸ‰ ëª©ë¡] ---\n\n"
    column_headers = df.columns.tolist() 

    for index, row in df.iterrows():
        context += f"[{row[column_headers[0]]}]\n" 
        for col_name in column_headers[1:]:
            context += f"- {col_name}: {row[col_name]}\n"
        context += "\n"
            
    context += "--- [ì°¨ëŸ‰ ëª©ë¡ ë] ---"

except Exception as e:
    st.error(f"ğŸš¨ ì°¨ëŸ‰ ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    st.stop()


# --- 4. ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
if "model" not in st.session_state:
    st.session_state.model = genai.GenerativeModel('gemini-2.5-flash')

if "chat" not in st.session_state:
    st.session_state.chat = st.session_state.model.start_chat(history=[])

if "messages" not in st.session_state:
    st.session_state.messages = []

# í¼ ì œì¶œ ì—¬ë¶€ í™•ì¸ í”Œë˜ê·¸
if "form_submitted" not in st.session_state:
    st.session_state.form_submitted = False

# ì‚¬ìš©ì í”„ë¡œí•„ ì €ì¥ ë³€ìˆ˜
if "user_profile" not in st.session_state:
    st.session_state.user_profile = ""


# --- 5. ê³µí†µ í•¨ìˆ˜: AI ì‘ë‹µ ìƒì„± ë° ìŠ¤íŠ¸ë¦¬ë° ---
def generate_ai_response(user_input):
    # 1. ì‚¬ìš©ì ë©”ì‹œì§€ UI í‘œì‹œ ë° ì €ì¥
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    # 2. AI ì‘ë‹µ ìš”ì²­
    with st.chat_message("assistant"):
        with st.spinner("jetcarê°€ ì •ë³´ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤... ğŸš™ğŸ’¨"):
            try:
                # ìµœì¢… í”„ë¡¬í”„íŠ¸ ì¡°í•© (ì°¨ëŸ‰ì •ë³´ + ì‚¬ìš©ìí”„ë¡œí•„ + í˜„ì¬ì§ˆë¬¸)
                final_prompt = f"""
                {context}
                
                [í˜„ì¬ ìƒë‹´ ì¤‘ì¸ ê³ ê° í”„ë¡œí•„]
                {st.session_state.user_profile}
                
                [ì‚¬ìš©ì ì§ˆë¬¸]
                {user_input}
                
                [ì§€ì‹œ ì‚¬í•­]
                1. [í˜„ì¬ ìƒë‹´ ì¤‘ì¸ ê³ ê° í”„ë¡œí•„] ì •ë³´ë¥¼ ì ê·¹ì ìœ¼ë¡œ í™œìš©í•˜ì—¬ ë§ì¶¤í˜•ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
                   - ê³ ê°ì´ ì„ í˜¸í•˜ëŠ” 'ì°¨ê¸‰'ê³¼ 'ì°¨ì¢…'ì„ ìµœìš°ì„ ìœ¼ë¡œ ê³ ë ¤í•˜ì„¸ìš”.
                   - ë§Œì•½ í”„ë¡œí•„ ì •ë³´ê°€ 'ì •ë³´ ì—†ìŒ'ì´ë¼ë©´ ì¼ë°˜ì ì¸ ê¸°ì¤€ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
                2. [ì œíŠ¸ì¹´ í˜„ì¬ ë³´ìœ  ì°¨ëŸ‰ ëª©ë¡]ì—ì„œ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì°¨ëŸ‰ì´ ìˆë‹¤ë©´ ê·¸ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•íˆ ë‹µë³€í•˜ì„¸ìš”.
                3. ì°¨ëŸ‰ ë°ì´í„°ì— ì—†ëŠ” ë‚´ìš©ì€ ì¼ë°˜ì ì¸ ìë™ì°¨ ì§€ì‹ì„ í™œìš©í•´ ì¹œì ˆí•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.
                4. ì‚¬ìš©ìê°€ íŠ¹ì • ì°¨ëŸ‰ë²ˆí˜¸(ë˜ëŠ” ì°¨ëŸ‰ëª…)ë¥¼ ë¬¼ì–´ë³´ë©´ ì•„ë˜ ì„œì‹ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”.
                   'ì´ëŸ° ë¶„ë“¤ê»˜ ì¶”ì²œ !' ë¶€ë¶„ì€ [ê³ ê° í”„ë¡œí•„]ì„ ì°¸ê³ í•˜ì—¬ ì°½ì˜ì ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
                   
                   [ì°¨ëŸ‰ ìš”ì•½ ì„œì‹]
                   ì œì¡°ì‚¬ ì—°ì‹ ì°¨ëŸ‰ëª… ì‹ ìš© ë¬´ê´€ ì „êµ­ ì¶œê³  
                   ... (ê¸°ì¡´ ìƒì„¸ ì„œì‹ ìœ ì§€) ...
                   ğŸ‘ ì´ëŸ° ë¶„ë“¤ê»˜ ì¶”ì²œ ! 
                   âœ”ï¸ (ê³ ê° í”„ë¡œí•„ì— ë§ì¶° ì‘ì„± 1)
                   âœ”ï¸ (ê³ ê° í”„ë¡œí•„ì— ë§ì¶° ì‘ì„± 2)
                   ...
                   
                5. ì¶”ì²œ ì°¨ëŸ‰ì´ ì—¬ëŸ¬ ëŒ€ì¼ ê²½ìš°, ê° ì°¨ëŸ‰ì˜ íŠ¹ì§•ì„ ë¹„êµí•´ ì£¼ì„¸ìš”.
                6. ê°€ê²©ì€ ê°€ì¥ ë‚®ì€ ê°€ê²©ì„ ê¸°ì¤€ìœ¼ë¡œ ì•ˆë‚´í•˜ì„¸ìš”.
                """

                # ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­
                response_stream = st.session_state.chat.send_message(
                    final_prompt,
                    stream=True
                )
                
                # í…ìŠ¤íŠ¸ ì¶”ì¶œ ì œë„ˆë ˆì´í„°
                def stream_text_generator(stream):
                    for chunk in stream:
                        if chunk.text:
                            yield chunk.text

                # ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ ë° ì €ì¥
                ai_response = st.write_stream(stream_text_generator(response_stream))
                st.session_state.messages.append({"role": "assistant", "content": ai_response})
                
            except Exception as e:
                st.error(f"AI ì‘ë‹µ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")


# --- 6. ë©”ì¸ UI ë¡œì§ ---

# (A) ì•„ì§ ì •ë³´ë¥¼ ì œì¶œí•˜ì§€ ì•Šì€ ê²½ìš° -> 'ì…ë ¥ í¼' í‘œì‹œ
if not st.session_state.form_submitted:
    st.info("ğŸ‘‹ ì•ˆë…•í•˜ì„¸ìš”! ê³ ê°ë‹˜ê»˜ ë”± ë§ëŠ” ì°¨ëŸ‰ì„ ì¶”ì²œí•´ ë“œë¦¬ê¸° ìœ„í•´ ê¸°ë³¸ ì •ë³´ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
    
    with st.form("consultation_form"):
        # 1. ê³ ê° ê¸°ë³¸ ì •ë³´ ì„¹ì…˜
        st.markdown('<div class="form-header">ğŸ‘¤ ê³ ê° ê¸°ë³¸ ì •ë³´</div>', unsafe_allow_html=True)
        col1, col2 = st.columns(2)
        
        with col1:
            age = st.selectbox("ë‚˜ì´", ["ë§Œ 26~35ì„¸", "ë§Œ 36~45ì„¸", "ë§Œ 46~55ì„¸", "ë§Œ 55ì„¸ ì´ìƒ"])
            marital_status = st.radio("ê²°í˜¼ ìœ ë¬´", ["ë¯¸í˜¼", "ê¸°í˜¼ (ìë…€ ì—†ìŒ)", "ê¸°í˜¼ (ìë…€ ìˆìŒ)"], horizontal=True)
        
        with col2:
            income = st.selectbox("ì›” ê¸‰ì—¬ ìˆ˜ì¤€ (ì„¸í›„)", ["200ë§Œì› ë¯¸ë§Œ", "200~300ë§Œì›", "300~400ë§Œì›", "400~500ë§Œì›", "500ë§Œì› ì´ìƒ"])
            purpose = st.multiselect("ì°¨ëŸ‰ ì‚¬ìš© ìš©ë„", ["ì¶œí‡´ê·¼ìš©", "ì˜ì—…/ì—…ë¬´ìš©", "íŒ¨ë°€ë¦¬ì¹´(ê°€ì¡±ì—¬í–‰)", "ë ˆì €/ìº í•‘", "ì¥ë³´ê¸°/ë§ˆì‹¤ìš©", "ê¸°íƒ€"])
        
        # ê¸°íƒ€ ìš©ë„ ì…ë ¥
        custom_purpose = st.text_input("ê¸°íƒ€ ìš©ë„ (ìœ„ì—ì„œ 'ê¸°íƒ€' ì„ íƒ ì‹œ ì‘ì„±)", placeholder="ì˜ˆ: ë‚šì‹œìš©, ëŒ€í˜•ê²¬ íƒ‘ìŠ¹ ë“±")
        
        st.markdown("---")
        
        # 2. í¬ë§ ì°¨ëŸ‰ ì •ë³´ ì„¹ì…˜
        st.markdown('<div class="form-header">ğŸš˜ í¬ë§ ì°¨ëŸ‰ ì •ë³´</div>', unsafe_allow_html=True)
        col3, col4 = st.columns(2)
        
        with col3:
            # ğŸš¨ [ìˆ˜ì •] default ì œê±° -> ë¹ˆì¹¸ìœ¼ë¡œ ì‹œì‘ ('ìƒê´€ì—†ìŒ'ì€ ì„ íƒì§€ì— ì¡´ì¬)
            preferred_size = st.multiselect("ì„ í˜¸ ì°¨ê¸‰ (ë³µìˆ˜ ì„ íƒ ê°€ëŠ¥)", ["ê²½ì°¨/ì¤€ì¤‘í˜•", "ì¤‘í˜•", "ëŒ€í˜•", "ìƒê´€ì—†ìŒ"])
        
        with col4:
            # ğŸš¨ [ìˆ˜ì •] default ì œê±° -> ë¹ˆì¹¸ìœ¼ë¡œ ì‹œì‘
            preferred_type = st.multiselect("ì„ í˜¸ ì°¨ì¢… (ë³µìˆ˜ ì„ íƒ ê°€ëŠ¥)", ["ì„¸ë‹¨", "SUV", "RV/ìŠ¹í•©", "ìƒê´€ì—†ìŒ"])

        st.markdown("---")
        st.markdown("### ğŸ’¬ ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?")
        
        initial_query = st.text_area("ê¶ê¸ˆí•œ ì ì´ ìˆë‹¤ë©´ ì ì–´ì£¼ì„¸ìš” (ë¹ˆì¹¸ìœ¼ë¡œ ë‘ì‹œë©´ ì…ë ¥í•œ ì •ë³´ì— ë§ì¶° ì¶”ì²œí•´ ë“œë¦½ë‹ˆë‹¤!)", height=80)
        
        btn_col1, btn_col2 = st.columns(2)
        
        with btn_col1:
            submit_with_info = st.form_submit_button("ğŸš€ ì •ë³´ ì…ë ¥í•˜ê³  ìƒë‹´ë°›ê¸°", use_container_width=True)
            
        with btn_col2:
            submit_skip = st.form_submit_button("â© ì…ë ¥ ì—†ì´ ë°”ë¡œ ì‹œì‘í•˜ê¸°", use_container_width=True)
        
        # [ë¡œì§ ì²˜ë¦¬]
        if submit_with_info:
            # 1. ì •ë³´ ì…ë ¥ ëª¨ë“œ
            
            final_purpose_list = purpose
            if custom_purpose.strip():
                final_purpose_list.append(f"ì¶”ê°€ìš©ë„: {custom_purpose}")
            
            # ğŸš¨ [ìˆ˜ì •] ë¦¬ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìœ¼ë©´(ì„ íƒ ì•ˆ í–ˆìœ¼ë©´) ìë™ìœ¼ë¡œ 'ìƒê´€ì—†ìŒ'ìœ¼ë¡œ ì²˜ë¦¬
            size_str = ", ".join(preferred_size) if preferred_size else "ìƒê´€ì—†ìŒ"
            type_str = ", ".join(preferred_type) if preferred_type else "ìƒê´€ì—†ìŒ"

            profile_text = f"""
            - ë‚˜ì´: {age}
            - ê²°í˜¼ ìœ ë¬´: {marital_status}
            - ì›” ê¸‰ì—¬: {income}
            - ì‚¬ìš© ìš©ë„: {', '.join(final_purpose_list)}
            - ì„ í˜¸ ì°¨ê¸‰: {size_str}
            - ì„ í˜¸ ì°¨ì¢…: {type_str}
            """
            st.session_state.user_profile = profile_text
            st.session_state.form_submitted = True
            
            if initial_query.strip():
                st.session_state.first_query = initial_query
            else:
                st.session_state.first_query = "ì œ í”„ë¡œí•„(ë‚˜ì´, ê¸‰ì—¬, ìš©ë„, ì„ í˜¸ ì°¨ê¸‰/ì°¨ì¢…)ì— ë”± ë§ëŠ” ì°¨ëŸ‰ì„ ì¶”ì²œí•´ ì£¼ì„¸ìš”. ì™œ ì¶”ì²œí•˜ëŠ”ì§€ë„ ì„¤ëª…í•´ ì£¼ì„¸ìš”."
            
            st.rerun()

        elif submit_skip:
            # 2. ê±´ë„ˆë›°ê¸° ëª¨ë“œ
            st.session_state.user_profile = "ì •ë³´ ì—†ìŒ (ì¼ë°˜ì ì¸ ê³ ê° ê¸°ì¤€ìœ¼ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”)"
            st.session_state.form_submitted = True
            
            if initial_query.strip():
                st.session_state.first_query = initial_query
            else:
                st.session_state.messages.append({"role": "assistant", "content": "ì œíŠ¸ì¹´ì— ëŒ€í•´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”! ğŸš—"})
                
            st.rerun()

# (B) ì •ë³´ë¥¼ ì œì¶œ(ë˜ëŠ” ê±´ë„ˆë›°ê¸°)í•œ í›„ -> 'ì±„íŒ… ì°½' í‘œì‹œ
else:
    # 1. ì´ì „ ëŒ€í™” ê¸°ë¡ í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # 2. (í¼ì—ì„œ ë„˜ì–´ì˜¨) ì²« ë²ˆì§¸ ì§ˆë¬¸ì´ ìˆë‹¤ë©´ ì²˜ë¦¬
    if "first_query" in st.session_state:
        query = st.session_state.first_query
        del st.session_state.first_query 
        generate_ai_response(query)

    # 3. ì±„íŒ… ì…ë ¥ì°½ í™œì„±í™”
    if prompt := st.chat_input("ì¶”ê°€ë¡œ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹ ê°€ìš”?"):
        generate_ai_response(prompt)
