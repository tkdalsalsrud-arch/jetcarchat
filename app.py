import streamlit as st
import google.generativeai as genai
import os
import pandas as pd # 'pandas' (CSV/Excel ë¦¬ë”ê¸°)
from pathlib import Path

# --- 1. API í‚¤ ì„¤ì • (ì˜¤ì§ Gemini í‚¤ í•˜ë‚˜ë§Œ!) ---
try:
    # Secretsì—ì„œ API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
except Exception as e:
    # ë¡œì»¬ secrets.toml íŒŒì¼ì´ ì—†ê±°ë‚˜ í‚¤ê°€ ì˜ëª»ë˜ì—ˆì„ ë•Œ
    st.error("ğŸš¨ [Gemini API í‚¤]ë¥¼ ì„¤ì •í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. Secretsë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    st.stop() # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì•± ì‹¤í–‰ ì¤‘ì§€

# --- 2. ì•± ì œëª© ë° ëª¨ë¸ ì„¤ì • ---
st.title("ğŸš— jetcar ì±—ë´‡ (v5: Excel RAG)")
st.caption("Powered by Streamlit & Google Gemini")

# ğŸš¨ (ìƒˆ ê¸°ëŠ¥ v5) 'Excel ì°¸ê³  ìë£Œ' ë¶ˆëŸ¬ì˜¤ê¸°
try:
    # app.pyì™€ ê°™ì€ ìœ„ì¹˜ì— ìˆëŠ” 'cars_data.xlsx' íŒŒì¼ì„ ì½ìŠµë‹ˆë‹¤.
    context_file = Path("cars_data.xlsx") # ğŸš¨ .csvì—ì„œ .xlsxë¡œ ë³€ê²½
    if not context_file.exists():
        st.error("ğŸš¨ 'cars_data.xlsx' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. app.pyì™€ ê°™ì€ ìœ„ì¹˜ì— ë§Œë“¤ì–´ì£¼ì„¸ìš”.")
        st.stop()
    
    # ğŸš¨ (ìˆ˜ì •ëœ ë¶€ë¶„!) pd.read_excelì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    # ì—‘ì…€ íŒŒì¼ì„ ì½ê¸° ìœ„í•´ 'engine="openpyxl"'ì´ í•„ìš”í•©ë‹ˆë‹¤.
    df = pd.read_excel(context_file, engine="openpyxl")
    
    # 'ì°¸ê³  ìë£Œ'ë¥¼ LLMì´ ì´í•´í•˜ê¸° ì‰¬ìš´ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    context = "--- [jetcar ì°¸ê³  ìë£Œ] ---\n\n"
    
    # CSV ë²„ì „(v4)ê³¼ ë™ì¼: ëª¨ë“  ì—´ ì œëª©ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    column_headers = df.columns.tolist() 

    for index, row in df.iterrows():
        # ì²« ë²ˆì§¸ ì—´ì˜ ê°’ì„ 'ì œëª©'ì²˜ëŸ¼ ì‚¬ìš© (ì˜ˆ: ì°¨ëŸ‰ëª…)
        context += f"[{row[column_headers[0]]}]\n" 
        
        # ë‚˜ë¨¸ì§€ ëª¨ë“  ì—´ì˜ ì •ë³´ë¥¼ 'í‚¤: ê°’' ìŒìœ¼ë¡œ ë™ì  ì¶”ê°€
        for col_name in column_headers[1:]: # ì²« ë²ˆì§¸ ì—´ ì œì™¸
            context += f"- {col_name}: {row[col_name]}\n"
        
        context += "\n" # ê° í•­ëª© ì‚¬ì´ì— ì¤„ë°”ê¿ˆ ì¶”ê°€
            
    context += "--- [ì°¸ê³  ìë£Œ ë] ---"

    st.info("âœ… 'cars_data.xlsx' (ì°¨ëŸ‰ ì •ë³´) ë¡œë”© ì™„ë£Œ!")

except Exception as e:
    st.error(f"ğŸš¨ 'cars_data.xlsx' íŒŒì¼ ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    st.stop()


# ì„¸ì…˜ ìƒíƒœ(session_state)ì— ëª¨ë¸ê³¼ ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™”
if "model" not in st.session_state:
    # 1.0 ì„¸ëŒ€ì˜ í‘œì¤€ ëª¨ë¸
    st.session_state.model = genai.GenerativeModel('gemini-2.5-pro')

if "chat" not in st.session_state:
    # ëª¨ë¸ì˜ ì±„íŒ… ì„¸ì…˜ ì‹œì‘ (ëŒ€í™” ê¸°ë¡ ìœ ì§€ë¥¼ ìœ„í•¨)
    st.session_state.chat = st.session_state.model.start_chat(history=[])

if "messages" not in st.session_state:
    # UIì— í‘œì‹œí•  ì±„íŒ… ê¸°ë¡
    st.session_state.messages = []

# --- 3. ì´ì „ ëŒ€í™” ë‚´ìš© í‘œì‹œ ---
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- 4. ì‚¬ìš©ì ì…ë ¥ ë° AI ì‘ë‹µ ì²˜ë¦¬ (v4ì™€ ë™ì¼) ---
if prompt := st.chat_input("ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”"):
    
    # 1. ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥ ë° UIì— í‘œì‹œ
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # 2. AIì—ê²Œ ì‘ë‹µ ìš”ì²­ (ğŸš¨ 'ì°¸ê³  ìë£Œ'ì™€ í•¨ê»˜ ì§ˆë¬¸í•˜ë„ë¡ ìˆ˜ì •ë¨)
    with st.spinner("jetcarê°€ ìƒê° ì¤‘... ğŸš™ğŸ’¨"):
        try:
            # ğŸš¨ 'ì°¸ê³  ìë£Œ'ì™€ 'ì§ˆë¬¸'ì„ í•©ì³ì„œ 'ì˜¤í”ˆë¶ ì‹œí—˜' ë¬¸ì œë¡œ ë§Œë“­ë‹ˆë‹¤.
            final_prompt = f"""
            {context}
            
            [ì‚¬ìš©ì ì§ˆë¬¸]
            {prompt}
            
            [ì§€ì‹œ]
            ìœ„ [jetcar ì°¸ê³  ìë£Œ]ì— ê¸°ë°˜í•´ì„œ [ì‚¬ìš©ì ì§ˆë¬¸]ì— ëŒ€ë‹µí•´ ì¤˜. 
            ë§Œì•½ [ì°¸ê³  ìë£Œ]ì— ë‹µì´ ì—†ë‹¤ë©´, "ì œê°€ ì•„ëŠ” ì •ë³´ ì¤‘ì—ëŠ” ì—†ìŠµë‹ˆë‹¤."ë¼ê³  ëŒ€ë‹µí•´.
            """

            # chat.send_messageë¥¼ ì‚¬ìš©í•´ì•¼ ëŒ€í™” ë§¥ë½ì´ ìœ ì§€ë©ë‹ˆë‹¤.
            response = st.session_state.chat.send_message(final_prompt)
            
            # 3. AI ì‘ë‹µ ì €ì¥ ë° UIì— í‘œì‹œ
            ai_response = response.text
            st.session_state.messages.append({"role": "assistant", "content": ai_response})
            with st.chat_message("assistant"):
                st.markdown(ai_response)
                
        except Exception as e:
            st.error(f"AI ì‘ë‹µ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")